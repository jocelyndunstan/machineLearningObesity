{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import packages and functions\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "#Import dataset and slicing\n",
    "dataset = pd.read_csv('dataset.csv', sep=',')\n",
    "countries = dataset.country_name[:79]\n",
    "continents = dataset.continent[:79]\n",
    "foods_ori = dataset.iloc[:79,4:] \n",
    "\n",
    "#Correlation analysys\n",
    "fc = foods_ori.corr(method='spearman', min_periods=1).abs()\n",
    "corr_matrix = fc.abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "foods_ori = dataset.iloc[:,4:] \n",
    "food_clean = foods_ori.drop(to_drop, axis=1)\n",
    "to_drop_pair = [] \n",
    "for food_col in to_drop:\n",
    "    food_col_pair = upper.idxmax()[food_col]\n",
    "    to_drop_pair.append(food_col_pair)\n",
    "    food_clean [str(food_col)+'+'+str(food_col_pair)] = (foods_ori[food_col] + foods_ori[food_col_pair])/2\n",
    "food_clean = food_clean.drop(to_drop_pair, axis=1)\n",
    "print('Columns to remove: ')\n",
    "print(to_drop, to_drop_pair)\n",
    "\n",
    "\n",
    "#Data slicing after correlation analysys\n",
    "foods = food_clean.iloc[:79,:] \n",
    "prevalencias = todo.prevalence_lancet[:79]\n",
    "\n",
    "#Standarization\n",
    "standard_foods = StandardScaler().fit(foods)\n",
    "foods_norm = standard_foods.transform(foods)\n",
    "prevalences = prevalencias.values.ravel()\n",
    "prevalences = (prevalences - np.mean(prevalences))/np.std(prevalences)\n",
    "\n",
    "#Principal Component Analysis\n",
    "pca = PCA(n_components=foods_norm.shape[1])\n",
    "pca_result = pca.fit_transform(foods_norm)\n",
    "suma = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "#LOOCV function\n",
    "def LOOCV(X,y,model,n_countries):\n",
    "\tytest = [None]*n_countries\n",
    "\typred_all = [None]*n_countries\n",
    "\tfor i in range(0,n_countries):\n",
    "\t    X_test = X[i,:]\n",
    "\t    y_test = y[i]\n",
    "\t    X_train = X[np.arange(len(X))!=i]\n",
    "\t    y_train = y[np.arange(len(y))!=i]\n",
    "\t    Reg = model.fit(X_train, y_train)\n",
    "\t    Reg_predicted=Reg.predict(X_test.reshape(1,-1))\n",
    "\t    ytest[i] = y_test\n",
    "\t    ypred_all[i] = Reg_predicted\n",
    "\n",
    "\terr = [None]*len(ypred_all)\n",
    "\tfor i in range(len(ypred_all)):\n",
    "\t    err[i] = np.square((ypred_all[i]-ytest[i]))\n",
    "\n",
    "    return err, ytest, ypred_all\n",
    "\n",
    "n_countries=79\n",
    "\n",
    "#Support Vector Machine\n",
    "svr_mod = LOOCV(X=foods,y=prevalences,model=svm.SVR(C=0.1,gamma=0.01,kernel='rbf'),n_countries=79)\n",
    "err_svr = svr_mod[0]\n",
    "print('SVR')\n",
    "print(f'MSE1: {np.mean(err_svr)}')\n",
    "print(f'RMSE: {np.sqrt(np.mean(err_svr))}')\n",
    "\n",
    "#Random Forest\n",
    "rf = LOOCV(X=foods,y=prevalences,model=RandomForestRegressor(max_depth = 9,  \n",
    "\t\t\t\t\t\t\t\tn_estimators=100).fit(X_train, y_train),n_countries=79)\n",
    "err_rf = rf[0]\n",
    "print('RF')\n",
    "print(f'MSE1: {np.mean(err_rf)}')\n",
    "print(f'RMSE: {np.sqrt(np.mean(err_rf))}')\n",
    "\n",
    "#XGBoost\n",
    "xgboost = LOOCV(X=foods,y=prevalences,model=xgb.XGBRegressor(colsample_bytree=0.35, max_depth=5, n_estimators=1250,\n",
    "                          \t\t\tmin_child_weight=5,gamma=0,subsample=0.9,reg_alpha=0.0001,\n",
    "                          \t\t\treg_lambda=1,learning_rate=0.1).fit(X_train, y_train),n_countries=79)\n",
    "err_xgb = xgboost[0]\n",
    "print('XGBr')\n",
    "print(f'MSE1: {np.mean(err_xgb)}')\n",
    "print(f'RMSE: {np.sqrt(np.mean(err_xgb))}')\n",
    "\n",
    "#Variable Importance List\n",
    "rfReg = RandomForestRegressor(max_depth = 9,n_estimators=1000, max_features=20) \n",
    "rf_vil  = [None]*250\n",
    "for i in range(0,250):\n",
    "    rf = rfReg.fit(foods,prevalences)\n",
    "    rf_vil[i] = rf.feature_importances_\n",
    "media_rf = np.mean(rf_vil, axis = 0)\n",
    "df_rf = pd.DataFrame({'variables':food_clean.columns, 'RF':media_rf}).sort_values(by=['RF'], ascending=True)\n",
    "\n",
    "\n",
    "#Prediction of Top 5,10,15,20\n",
    "df_model = df_rf\n",
    "largo = len(df_model)\n",
    "no_rf_top5 = df_model.iloc[:(largo-5),1].values  \n",
    "no_rf_top10 = df_model.iloc[:(largo-10),1].values \n",
    "no_rf_top15 = df_model.iloc[:(largo-15),1].values\n",
    "no_rf_top20 = df_model.iloc[:(largo-20),1].values\n",
    "foods_df = pd.DataFrame(foods)\n",
    "foods_df.columns = food_clean.columns\n",
    "top5 = foods_df.drop(no_rf_top5, axis=1)\n",
    "top10 = foods_df.drop(no_rf_top10, axis=1)\n",
    "top15 = foods_df.drop(no_rf_top15, axis=1)\n",
    "top20 = foods_df.drop(no_rf_top20, axis=1)\n",
    "scaler.fit(top5)\n",
    "top5_normalised = scaler.transform(top5)\n",
    "scaler.fit(top10)\n",
    "top10_normalised = scaler.transform(top10)\n",
    "scaler.fit(top15)\n",
    "top15_normalised = scaler.transform(top15)\n",
    "scaler.fit(top20)\n",
    "top20_normalised = scaler.transform(top20)\n",
    "\n",
    "#Prediction Top5\n",
    "top_5 = LOOCV(X=top5_normalised,y=prevalences,model= RandomForestRegressor(max_depth = 9,n_estimators=100),n_countries=79)\n",
    "err5 = top_5[0]\n",
    "\n",
    "#Prediction Top10\n",
    "top_10 = LOOCV(X=top10_normalised,y=prevalences,model= RandomForestRegressor(max_depth = 9,n_estimators=100),n_countries=79)\n",
    "err10 = top_10[0]\n",
    "\n",
    "#Prediction Top15\n",
    "top_15 = LOOCV(X=top15_normalised,y=prevalences,model= RandomForestRegressor(max_depth = 9,n_estimators=100),n_countries=79)\n",
    "err15 = top_15[0]\n",
    "\n",
    "#Prediction Top20\n",
    "top_20 = LOOCV(X=top20_normalised,y=prevalences,model= RandomForestRegressor(max_depth = 9,n_estimators=100),n_countries=79)\n",
    "err20 = top_20[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
